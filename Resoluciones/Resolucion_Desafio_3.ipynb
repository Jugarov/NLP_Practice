{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccaedb43",
   "metadata": {},
   "source": [
    "## Sugerencias para la resolución\n",
    "- Durante el entrenamiento, guiarse por el descenso de la perplejidad en los datos de validación para finalizar el entrenamiento. Para ello se provee un callback.\n",
    "- Explorar utilizar SimpleRNN (celda de Elman), LSTM y GRU.\n",
    "- rmsprop es el optimizador recomendado para la buena convergencia. No obstante se pueden explorar otros.\n",
    "\n",
    "## Consignas del Desafío 3\n",
    "\n",
    "### 1. Seleccionar un corpus de texto sobre el cual entrenar el modelo de lenguaje."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8ed8c4",
   "metadata": {},
   "source": [
    "### 2. Realizar el pre-procesamiento adecuado para tokenizar el corpus, estructurar el dataset y separar entre datos de entrenamiento y validación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83767482",
   "metadata": {},
   "source": [
    "### 3. Proponer arquitecturas de redes neuronales basadas en unidades recurrentes para implementar un modelo de lenguaje."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abcd845",
   "metadata": {},
   "source": [
    "### 4. Con el o los modelos que consideren adecuados, generar nuevas secuencias a partir de secuencias de contexto con las estrategias de greedy search y beam search determístico y estocástico. En este último caso observar el efecto de la temperatura en la generación de secuencias."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
