{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b482feff",
   "metadata": {},
   "source": [
    "## Consignas del desafío 4\n",
    "\n",
    "Construir un traductor inglés-español.\n",
    "\n",
    "---\n",
    "\n",
    "## Desarrollo\n",
    "\n",
    "### 1. Obtención del Dataset\n",
    "\n",
    "Para entrenar un traductor basado en un modelo LSTM se necesita primero un dataset como el que provee la cátedra: [Anki](https://www.manythings.org/anki/).\n",
    "Este dataset se compone de 118964 expresiones distintas escritas en inglés seguido de su traducción en español. La propia página de referencia indica que la estructura sigue un formato `English + TAB + The Other Language`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50a124cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Campos disponibles en el primer ejemplo: dict_keys(['en', 'es'])\n",
      "\n",
      "Primeros 2 ejemplos (campos y longitudes en palabras):\n",
      "\n",
      "Ejemplo 1:\n",
      "  en: 1 palabras\n",
      "  es: 1 palabras\n",
      "\n",
      "Ejemplo 2:\n",
      "  en: 1 palabras\n",
      "  es: 1 palabras\n",
      "\n",
      "--- Estadísticas del dataset ---\n",
      "Número total de ejemplos: 118964\n",
      "Número de ejemplos con campos vacíos:\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "text_file = \"./spa.txt\"\n",
    "\n",
    "# Leer archivo línea por línea y separar inglés y español\n",
    "pairs = []\n",
    "with open(text_file, encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue  # saltar líneas vacías\n",
    "        if '\\t' not in line:\n",
    "            continue  # saltar líneas sin tab\n",
    "        en, es = line.split('\\t')[:2]  # tomar solo los dos primeros campos\n",
    "        pairs.append({'en': en, 'es': es})\n",
    "\n",
    "# Ahora cada elemento es un diccionario, podemos hacer .keys()\n",
    "print(\"Campos disponibles en el primer ejemplo:\", pairs[0].keys())\n",
    "\n",
    "# Inicializar contadores\n",
    "field_lengths = Counter()\n",
    "num_empty = Counter()\n",
    "num_examples = len(pairs)\n",
    "\n",
    "# Revisar primeros 2 ejemplos\n",
    "print(\"\\nPrimeros 2 ejemplos (campos y longitudes en palabras):\")\n",
    "for i, sample in enumerate(pairs[:2]):\n",
    "    print(f\"\\nEjemplo {i+1}:\")\n",
    "    for k, v in sample.items():\n",
    "        print(f\"  {k}: {len(v.split())} palabras\")\n",
    "        if len(v.strip()) == 0:\n",
    "            num_empty[k] += 1\n",
    "        field_lengths[k] += len(v.split())\n",
    "\n",
    "# Estadísticas generales\n",
    "print(\"\\n--- Estadísticas del dataset ---\")\n",
    "print(f\"Número total de ejemplos: {num_examples}\")\n",
    "print(\"Número de ejemplos con campos vacíos:\")\n",
    "for k, count in num_empty.items():\n",
    "    print(f\"  {k}: {count} ({count/num_examples*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debb8fc1",
   "metadata": {},
   "source": [
    "### 2. Preprocesamiento\n",
    "\n",
    "Los datos crudos deben ser preprocesados y normalizados para facilitar la posterior tokenización del vocabulario. Para ello, se procesa el texto de muestra para:\n",
    "\n",
    "1. Escribir todo el texto en letra minúscula, normalizar los espacios entre palabras y eliminar caracteres especiales.\n",
    "2. Añadir tokens especiales\n",
    "3. Limitar la longitud de las estructuras encoder/decoder\n",
    "4. Filtrar ejemplos vacíos o muy largos\n",
    "\n",
    "Para entrenar luego el modelo encoder-decoder, se prepara el dataset de modo que la entrada de ejemplo del encoder sea la expresión en inglés y como target de salida del decoder la traducción de esa expresión al español."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3276532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeros 3 pares encoder-decoder:\n",
      "EN: go.\n",
      "ES: ve.\n",
      "\n",
      "EN: go.\n",
      "ES: vete.\n",
      "\n",
      "EN: go.\n",
      "ES: vaya.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import pickle\n",
    "import collections\n",
    "import os\n",
    "\n",
    "# ------------------------\n",
    "# Configuración\n",
    "# ------------------------\n",
    "TEXT_FILE = \"spa.txt\"\n",
    "OUTPUT_DIR = \"traductor\"\n",
    "MAX_LEN_ENCODER = 128\n",
    "MAX_LEN_DECODER = 64\n",
    "MIN_FREQ = 3\n",
    "VOCAB_SIZE = 30000\n",
    "\n",
    "SPECIAL_TOKENS = {\n",
    "    \"pad\": \"<pad>\",\n",
    "    \"unk\": \"<unk>\",\n",
    "    \"sos\": \"<sos>\",\n",
    "    \"eos\": \"<eos>\",\n",
    "    \"sep\": \"<sep>\",\n",
    "}\n",
    "\n",
    "# ------------------------\n",
    "# Normalización básica\n",
    "# ------------------------\n",
    "def normalize_text(s):\n",
    "    s = s.lower()\n",
    "    s = re.sub(r\"[^a-zA-Z0-9áéíóúüñ!?.,' ]+\", \" \", s)  # mantener acentos y símbolos comunes\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "# ------------------------\n",
    "# Construcción dataset\n",
    "# ------------------------\n",
    "def build_examples(data):\n",
    "    \"\"\"\n",
    "    Convierte lista de diccionarios {'en': ..., 'es': ...}\n",
    "    en pares (encoder_input, decoder_target) normalizados.\n",
    "    \"\"\"\n",
    "    examples = []\n",
    "    for sample in data:\n",
    "        en_text = sample.get(\"en\", \"\").strip()\n",
    "        es_text = sample.get(\"es\", \"\").strip()\n",
    "        if not en_text or not es_text:\n",
    "            continue\n",
    "\n",
    "        # normalizar\n",
    "        en_text_norm = normalize_text(en_text)\n",
    "        es_text_norm = normalize_text(es_text)\n",
    "\n",
    "        examples.append({\n",
    "            \"encoder_text\": en_text_norm,\n",
    "            \"decoder_text\": es_text_norm\n",
    "        })\n",
    "\n",
    "    return examples\n",
    "\n",
    "# Construir pares encoder-decoder\n",
    "examples = build_examples(pairs)\n",
    "\n",
    "# Revisar algunos ejemplos\n",
    "print(\"Primeros 3 pares encoder-decoder:\")\n",
    "for ex in examples[:3]:\n",
    "    print(f\"EN: {ex['encoder_text']}\")\n",
    "    print(f\"ES: {ex['decoder_text']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385f6f72",
   "metadata": {},
   "source": [
    "### 3. Tokenización\n",
    "\n",
    "Tras limpiar el contenido de las conversaciones, normalizar el texto y separar las entradas y salidas del encoder y del decoder, se continúa con la tokenización del texto y la generación de diccionarios para trabajar con secuencias más aptas para el uso de modelos. Para un manejo del lenguaje más robusto y naturalizado, así como para evitar `<unk>`, se tokeniza el corpus utilizando la librería *spaCy* como se muestra a continuación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff356021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Preprocesamiento completo\n",
      "{'num_examples': 118964, 'vocab_size': 17982, 'max_len_encoder': 128, 'max_len_decoder': 64}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "import spacy\n",
    "\n",
    "# ------------------------\n",
    "# Cargar modelo spaCy\n",
    "# ------------------------\n",
    "# Descargar modelo si no lo tenés:\n",
    "# python -m spacy download en_core_web_sm\n",
    "nlp_en = spacy.load(\"en_core_web_sm\")\n",
    "nlp_es = spacy.load(\"es_core_news_sm\")\n",
    "\n",
    "\n",
    "# ------------------------\n",
    "# Tokenización con spaCy\n",
    "# ------------------------\n",
    "def tokenize_en(text):\n",
    "    \"\"\"\n",
    "    Tokeniza un texto usando spaCy.\n",
    "    Devuelve una lista de tokens limpios.\n",
    "    Compatible con embeddings FastText.\n",
    "    \"\"\"\n",
    "    doc = nlp_en(text)\n",
    "    tokens = [token.text.lower() for token in doc if not token.is_space]\n",
    "    return tokens\n",
    "\n",
    "def tokenize_es(text):\n",
    "    \"\"\"\n",
    "    Tokeniza un texto usando spaCy.\n",
    "    Devuelve una lista de tokens limpios.\n",
    "    Compatible con embeddings FastText.\n",
    "    \"\"\"\n",
    "    doc = nlp_es(text)\n",
    "    tokens = [token.text.lower() for token in doc if not token.is_space]\n",
    "    return tokens\n",
    "\n",
    "def build_vocab(examples):\n",
    "    counter = collections.Counter()\n",
    "    for ex in examples:\n",
    "        counter.update(tokenize_en(ex[\"encoder_text\"]))\n",
    "        counter.update(tokenize_es(ex[\"decoder_text\"]))\n",
    "\n",
    "    # aplicar min_freq\n",
    "    tokens = [tok for tok, c in counter.items() if c >= MIN_FREQ]\n",
    "    tokens = tokens[:VOCAB_SIZE - len(SPECIAL_TOKENS)]\n",
    "\n",
    "    vocab = list(SPECIAL_TOKENS.values()) + tokens\n",
    "    token2id = {tok: i for i, tok in enumerate(vocab)}\n",
    "    id2token = {i: tok for tok, i in token2id.items()}\n",
    "    return token2id, id2token\n",
    "\n",
    "def numericalize(tokens, token2id, max_len, is_decoder=False):\n",
    "    ids = []\n",
    "    if is_decoder:\n",
    "        ids.append(token2id[SPECIAL_TOKENS[\"sos\"]])\n",
    "    for t in tokens:\n",
    "        ids.append(token2id.get(t, token2id[SPECIAL_TOKENS[\"unk\"]]))\n",
    "    if is_decoder:\n",
    "        ids.append(token2id[SPECIAL_TOKENS[\"eos\"]])\n",
    "\n",
    "    length = len(ids)\n",
    "    ids = ids[:max_len]\n",
    "\n",
    "    while len(ids) < max_len:\n",
    "        ids.append(token2id[SPECIAL_TOKENS[\"pad\"]])\n",
    "\n",
    "    return ids, min(length, max_len)\n",
    "\n",
    "# Vocabulario\n",
    "token2id, id2token = build_vocab(examples)\n",
    "\n",
    "processed = []\n",
    "for ex in examples:\n",
    "    enc_tokens = tokenize_en(ex[\"encoder_text\"])\n",
    "    dec_tokens = tokenize_es(ex[\"decoder_text\"])\n",
    "\n",
    "    enc_ids, enc_len = numericalize(enc_tokens, token2id, MAX_LEN_ENCODER)\n",
    "    dec_ids, dec_len = numericalize(dec_tokens, token2id, MAX_LEN_DECODER, is_decoder=True)\n",
    "\n",
    "    processed.append({\n",
    "        \"encoder_ids\": enc_ids,\n",
    "        \"encoder_len\": enc_len,\n",
    "        \"decoder_ids\": dec_ids,\n",
    "        \"decoder_len\": dec_len\n",
    "    })\n",
    "\n",
    "# Guardar\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "with open(f\"{OUTPUT_DIR}/token2id.pkl\", \"wb\") as f:\n",
    "    pickle.dump(token2id, f)\n",
    "with open(f\"{OUTPUT_DIR}/id2token.pkl\", \"wb\") as f:\n",
    "    pickle.dump(id2token, f)\n",
    "with open(f\"{OUTPUT_DIR}/dataset.pkl\", \"wb\") as f:\n",
    "    pickle.dump(processed, f)\n",
    "\n",
    "stats = {\n",
    "    \"num_examples\": len(processed),\n",
    "    \"vocab_size\": len(token2id),\n",
    "    \"max_len_encoder\": MAX_LEN_ENCODER,\n",
    "    \"max_len_decoder\": MAX_LEN_DECODER,\n",
    "}\n",
    "with open(f\"{OUTPUT_DIR}/stats.json\", \"w\") as f:\n",
    "    json.dump(stats, f, indent=2)\n",
    "\n",
    "def tokenizer(text):\n",
    "    return [tok.text.lower() for tok in nlp(text) if not tok.is_space]\n",
    "\n",
    "print(\"✅ Preprocesamiento completo\")\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0b5f5c",
   "metadata": {},
   "source": [
    "### 4. Embeddings\n",
    "\n",
    "Con los diccionarios de vocabulario ya creados, se codifican embeddings usando estos tokens como base y con ayuda del módulo `gensim.Fastext` de *Gensim*, que se elige por su robustez y capacidad de adaptación frente a palabras por fuera del vocabulario de muestra, lo cual es probable que ocurra en un bot conversacional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19429802",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "\n",
    "# Extraer todas las frases tokenizadas del dataset\n",
    "all_sentences = []\n",
    "\n",
    "for ex in processed:  # processed = lista de diccionarios con 'encoder_ids' y 'decoder_ids'\n",
    "    enc_tokens = [id2token[i] for i in ex['encoder_ids'] if i != token2id['<pad>']]\n",
    "    dec_tokens = [id2token[i] for i in ex['decoder_ids'] if i != token2id['<pad>']]\n",
    "    \n",
    "    all_sentences.append(enc_tokens)\n",
    "    all_sentences.append(dec_tokens)\n",
    "\n",
    "\n",
    "# Entrenar FastText\n",
    "ft_model = FastText(\n",
    "    sentences=all_sentences,\n",
    "    vector_size=100,   # dimensión de los embeddings\n",
    "    window=5,          # contexto\n",
    "    min_count=1,       # ya tenemos vocab, poner 1 para incluir todos los tokens\n",
    "    sg=1,              # 1 = skip-gram, 0 = CBOW\n",
    "    workers=4,\n",
    "    epochs=10\n",
    ")\n",
    "\n",
    "# Guardar modelo\n",
    "ft_model.save(\"fasttext_convai2.model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e5c0ab",
   "metadata": {},
   "source": [
    "Con el embedding ya creado, se traducen todos los tensores tokenizados a tensores con los embeddings que ha encontrado FastText, que serán los tensores con los que se alimenta el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fde5247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([17982, 100])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "vocab_size = len(token2id)\n",
    "embedding_dim = ft_model.vector_size\n",
    "\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "\n",
    "for token, idx in token2id.items():\n",
    "    if token in ft_model.wv:\n",
    "        embedding_matrix[idx] = ft_model.wv[token]\n",
    "    else:\n",
    "        embedding_matrix[idx] = np.random.normal(scale=0.6, size=(embedding_dim,))  # fallback\n",
    "\n",
    "embedding_matrix = torch.tensor(embedding_matrix, dtype=torch.float32)\n",
    "print(embedding_matrix.shape)  # (vocab_size, embedding_dim)\n",
    "\n",
    "embedding_layer = nn.Embedding.from_pretrained(embedding_matrix, freeze=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e01d7ee",
   "metadata": {},
   "source": [
    "### 5. Dataloaders\n",
    "\n",
    "Para entrenar el modelo encoder-decoder se facilita la ingesta de datos a través del armado de un Dataloader. Este dataloader debe devolver tensores `encoder_input` y `decoder_input` para el consumo de los datos y `decoder_target` como respuesta de validación con la que ajustar el modelo. Para ello, es necesario eliminar los tokens `<eos>` y `<sos>` en la entrada y salida del decoder, respectivamente; de modo que las listas de entrenamiento sean del mismo tamaño pero con un desfasaje entre ellas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f21cf954",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class BotDataset(Dataset):\n",
    "    def __init__(self, data, pad_idx):\n",
    "        self.data = data\n",
    "        self.pad_idx = pad_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ex = self.data[idx]\n",
    "        enc = ex[\"encoder_ids\"]\n",
    "        dec = ex[\"decoder_ids\"]\n",
    "\n",
    "        # Entrada al decoder: sin el último token (<eos>)\n",
    "        dec_input = dec[:-1]\n",
    "        # Target del decoder: sin el primero (<sos>)\n",
    "        dec_target = dec[1:]\n",
    "\n",
    "        return torch.tensor(enc, dtype=torch.long), torch.tensor(dec_input, dtype=torch.long), torch.tensor(dec_target, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1a3604",
   "metadata": {},
   "source": [
    "Como las secuencias tienen longitudes variables, se requiere construir un padding dinámico que llene los espacios vacíos cuando sea necesario. Esto se traduce en una *collate function* personalizada que permita hacer esto en la construcción de secuencias del Dataloader. La función de padding es un asset más que se utiliza directamente desde PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a6bba2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "PAD_TOKEN = \"<pad>\"\n",
    "SOS_TOKEN = \"<sos>\"\n",
    "EOS_TOKEN = \"<eos>\"\n",
    "PAD_IDX = token2id[PAD_TOKEN]\n",
    "SOS_IDX = token2id[SOS_TOKEN]\n",
    "EOS_IDX = token2id[EOS_TOKEN]\n",
    "\n",
    "def collate_fn(batch):\n",
    "    encoders, dec_inputs, dec_targets = zip(*batch)\n",
    "    \n",
    "    enc_padded = pad_sequence(encoders, batch_first=True, padding_value=PAD_IDX)\n",
    "    dec_in_padded = pad_sequence(dec_inputs, batch_first=True, padding_value=PAD_IDX)\n",
    "    dec_tgt_padded = pad_sequence(dec_targets, batch_first=True, padding_value=PAD_IDX)\n",
    "\n",
    "    return enc_padded, dec_in_padded, dec_tgt_padded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1169eab8",
   "metadata": {},
   "source": [
    "Habiendo creado estas estructuras, se genera el dataloader que tome como base los embeddings preparados, separando previamente el mismo en conjuntos de entrenamiento y validación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "698ba927",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "dataset = BotDataset(processed, PAD_IDX)\n",
    "\n",
    "# train-val split: 80/20 split\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_data, val_data = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_data, batch_size=32, shuffle=False, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e2c3bd",
   "metadata": {},
   "source": [
    "### 6. Estructura del modelo\n",
    "\n",
    "Con todos los datos de alimentación y comparación preparados, solo resta crear la estructura del modelo y entrenarlo. El modelo *seq2seq* consiste en un modelo many-to-many que traduce una secuencia de un tensor a otro, pero procesando todo el tensor de entrada a la vez y considerando la relación y orden de los elementos del tensor y no solo la aparición o no de los mismos. El mecanismo que produce esta transformación se basa en una arquitectura encoder-decoder, donde el segundo trata de recrear el mapeo que realiza el primero sobre la información de entrada para entender mejor el contexto de escritura en el que se trabaja para poder brindar una salida de mejor calidad.\n",
    "\n",
    "Como se mencionó antes, el orden de los elementos del tensor es relevante para poder obtener una mejor salida, por lo que la utilización de capas LSTM resulta de gran ayuda en la obtención de una salida de calidad.\n",
    "\n",
    "Se destaca que en lugar de entrenar la capa de embeddings desde cero como en un modelo normal, se importa la capa de embeddings ya generada con FastText para la codificación de los elementos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8a8eda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, embedding, hidden_size, num_layers=1, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.embedding = embedding\n",
    "        self.lstm = nn.LSTM(\n",
    "            embedding.embedding_dim,\n",
    "            hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0\n",
    "        )\n",
    "\n",
    "    def forward(self, src):\n",
    "        embedded = self.embedding(src)\n",
    "        outputs, (hidden, cell) = self.lstm(embedded)\n",
    "        return outputs, (hidden, cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78fccff",
   "metadata": {},
   "source": [
    "Para el decodificador se incorpora además un mecanismo de atención que permita al modelo tener más presente el contexto general de la conversación y no solo depender de la última información recibida. Vale la pena mencionar que se escoge una técnica de atención conocido como **[Atención Bahdanau](https://medium.com/@abhishekjainindore24/everything-about-attention-mechanism-bahdanau-attention-and-luong-attention-f76e63b702ca)**, que permite también destacar los tokens que más información aportan al contexto de la conversación que se está teniendo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "063a2570",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, enc_hidden_dim, dec_hidden_dim):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Linear(enc_hidden_dim + dec_hidden_dim, dec_hidden_dim)\n",
    "        self.v = nn.Linear(dec_hidden_dim, 1, bias=False)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs, mask=None):\n",
    "        # hidden: [batch, dec_hidden_dim]\n",
    "        # encoder_outputs: [batch, src_len, enc_hidden_dim]\n",
    "        src_len = encoder_outputs.shape[1]\n",
    "\n",
    "        # Repetir hidden para cada paso de la secuencia\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))  # [batch, src_len, dec_hidden_dim]\n",
    "        attention = self.v(energy).squeeze(2)  # [batch, src_len]\n",
    "\n",
    "        if mask is not None:\n",
    "            attention = attention.masked_fill(mask == 0, -1e10)\n",
    "\n",
    "        return F.softmax(attention, dim=1)\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, embedding, enc_hidden_dim, dec_hidden_dim, output_dim, attention, num_layers=1, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.embedding = embedding\n",
    "        self.attention = attention\n",
    "        self.lstm = nn.LSTM(\n",
    "            embedding.embedding_dim + enc_hidden_dim,\n",
    "            dec_hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0\n",
    "        )\n",
    "        self.fc_out = nn.Linear(enc_hidden_dim + dec_hidden_dim + embedding.embedding_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input, hidden, cell, encoder_outputs, mask=None):\n",
    "        input = input.unsqueeze(1)\n",
    "        embedded = self.dropout(self.embedding(input))  # [batch, 1, emb_dim]\n",
    "\n",
    "        attn_weights = self.attention(hidden[-1], encoder_outputs, mask).unsqueeze(1)  # [batch, 1, src_len]\n",
    "        context = torch.bmm(attn_weights, encoder_outputs)  # [batch, 1, enc_hidden_dim]\n",
    "\n",
    "        lstm_input = torch.cat((embedded, context), dim=2)\n",
    "        output, (hidden, cell) = self.lstm(lstm_input, (hidden, cell))\n",
    "\n",
    "        # Salida final\n",
    "        output_pred = self.fc_out(torch.cat((output, context, embedded), dim=2).squeeze(1))\n",
    "        return output_pred, hidden, cell, attn_weights.squeeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c3bfa2",
   "metadata": {},
   "source": [
    "La estructura del modelo completo seq2seq queda definido entonces como:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8244f0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqModel(nn.Module):\n",
    "    def __init__(self, encoder, decoder, pad_idx, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.pad_idx = pad_idx\n",
    "        self.device = device\n",
    "\n",
    "    def create_mask(self, src):\n",
    "        return (src != self.pad_idx).to(self.device)\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        batch_size = src.size(0)\n",
    "        trg_len = trg.size(1)\n",
    "        vocab_size = self.decoder.fc_out.out_features\n",
    "\n",
    "        outputs = torch.zeros(batch_size, trg_len, vocab_size).to(self.device)\n",
    "        encoder_outputs, (hidden, cell) = self.encoder(src)\n",
    "        mask = self.create_mask(src)\n",
    "        input = trg[:, 0]\n",
    "\n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden, cell, _ = self.decoder(input, hidden, cell, encoder_outputs, mask)\n",
    "            outputs[:, t] = output\n",
    "            top1 = output.argmax(1)\n",
    "            input = trg[:, t] if torch.rand(1).item() < teacher_forcing_ratio else top1\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0eab68d",
   "metadata": {},
   "source": [
    "### 7. Entrenamiento del modelo\n",
    "\n",
    "Con la estructura y los datos ya preparados, solo queda definir una función de entrenamiento para configurar el modelo. El uso de GPU acelera mucho el procesamiento de los datos para poder entrenarlo con el vocabulario entero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db66f57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train_epoch(model, dataloader, optimizer, criterion, device, clip=1.0):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for batch in tqdm(dataloader, desc=\"Entrenando\", leave=False):\n",
    "        src, trg_in, trg_out = [x.to(device) for x in batch]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, trg_in)  # [batch, trg_len, vocab_size]\n",
    "\n",
    "        # Ignorar el primer token (<sos>)\n",
    "        loss = criterion(output.view(-1, output.shape[-1]), trg_out.view(-1))\n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient clipping para estabilidad\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(dataloader)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for batch in tqdm(dataloader, desc=\"Validando\", leave=False):\n",
    "        src, trg_in, trg_out = [x.to(device) for x in batch]\n",
    "        with torch.no_grad():\n",
    "            output = model(src, trg_in)\n",
    "            loss = criterion(output.view(-1, output.shape[-1]), trg_out.view(-1))\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(dataloader)\n",
    "\n",
    "def train_model(model, train_loader, val_loader, optimizer, criterion, device, n_epochs=10, clip=1.0):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        train_loss = train_epoch(model, train_loader, optimizer, criterion, device, clip)\n",
    "        val_loss = evaluate(model, val_loader, criterion, device)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        print(f\"Epoch {epoch}/{n_epochs} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    # ---- Curvas de pérdida ----\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(train_losses, label=\"Train Loss\")\n",
    "    plt.plot(val_losses, label=\"Validation Loss\")\n",
    "    plt.title(\"Curvas de pérdida\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e35664",
   "metadata": {},
   "source": [
    "Por último, se inicializan todas las estructuras del modelo y se usa la función de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "858151df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 | Train Loss: 4.7500 | Val Loss: 3.8394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 | Train Loss: 3.4695 | Val Loss: 3.4110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 | Train Loss: 3.0452 | Val Loss: 3.2220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 | Train Loss: 2.8028 | Val Loss: 3.1623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 | Train Loss: 2.6382 | Val Loss: 3.1581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 | Train Loss: 2.5114 | Val Loss: 3.1510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 | Train Loss: 2.4156 | Val Loss: 3.1664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 | Train Loss: 2.3361 | Val Loss: 3.1994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 | Train Loss: 2.2683 | Val Loss: 3.2248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20 | Train Loss: 2.2115 | Val Loss: 3.2479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20 | Train Loss: 2.1643 | Val Loss: 3.2919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20 | Train Loss: 2.1191 | Val Loss: 3.3413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20 | Train Loss: 2.0801 | Val Loss: 3.3620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20 | Train Loss: 2.0494 | Val Loss: 3.4048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20 | Train Loss: 2.0154 | Val Loss: 3.4439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20 | Train Loss: 1.9875 | Val Loss: 3.4753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20 | Train Loss: 1.9617 | Val Loss: 3.5241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20 | Train Loss: 1.9412 | Val Loss: 3.5470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20 | Train Loss: 1.9220 | Val Loss: 3.5726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20 | Train Loss: 1.9022 | Val Loss: 3.6107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "INPUT_DIM = len(token2id)\n",
    "OUTPUT_DIM = len(token2id)\n",
    "HIDDEN_SIZE = 256\n",
    "NUM_LAYERS = 1\n",
    "DROPOUT = 0.3\n",
    "LR = 1e-3\n",
    "EPOCHS = 20\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Usando dispositivo:\", DEVICE)\n",
    "\n",
    "attn = Attention(HIDDEN_SIZE, HIDDEN_SIZE)\n",
    "encoder = Encoder(embedding_layer, HIDDEN_SIZE, NUM_LAYERS, DROPOUT)\n",
    "decoder = Decoder(embedding_layer, HIDDEN_SIZE, HIDDEN_SIZE, OUTPUT_DIM, attn, NUM_LAYERS, DROPOUT)\n",
    "\n",
    "model = Seq2SeqModel(encoder, decoder, PAD_IDX, DEVICE).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "\n",
    "train_losses, val_losses = train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    DEVICE,\n",
    "    n_epochs=EPOCHS,\n",
    "    clip=1.0\n",
    ")\n",
    "\n",
    "torch.save(model.state_dict(), \"seq2seq_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071520ab",
   "metadata": {},
   "source": [
    "### 8. Inferencia\n",
    "\n",
    "Con el modelo ya entrenado, se puede utilizar el mismo para inferir nuevas respuestas. Para generalizar un poco más las respuestas se usa un algoritmo *beam search* para entregar la frase de salida en lugar de una búsqueda *greedy* que puede llevar a \"alucinaciones\" en la respuesta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3770020f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Respuesta generada: reformas dinero a pasar de .\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def beam_search(model, src_tensor, src_len, vocab, beam_width=3, max_len=20, device=\"cuda\"):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        src_tensor = src_tensor.unsqueeze(0).to(device)\n",
    "        src_len = torch.tensor([src_len]).to(device)\n",
    "\n",
    "        encoder_outputs, (hidden, cell) = model.encoder(src_tensor)\n",
    "        \n",
    "        # Inicializamos el haz con el token <SOS>\n",
    "        beams = [(torch.tensor([[vocab[\"<sos>\"]]]).to(device), hidden, 0)]  # (seq, hidden, score)\n",
    "\n",
    "        for _ in range(max_len):\n",
    "            new_beams = []\n",
    "            for seq, hidden, score in beams:\n",
    "                last_token = seq[-1, -1].unsqueeze(0)\n",
    "\n",
    "                if last_token.item() == vocab[\"<eos>\"]:\n",
    "                    new_beams.append((seq, hidden, score))\n",
    "                    continue\n",
    "\n",
    "                output, hidden, cell, attn_weights = model.decoder(\n",
    "                    last_token, hidden, cell, encoder_outputs\n",
    "                )\n",
    "                log_probs = F.log_softmax(output, dim=1)\n",
    "\n",
    "                # Penalizar tokens desconocido en la respuesta\n",
    "                log_probs[:, vocab[\"<unk>\"]] -= 10.0\n",
    "\n",
    "                # Expandimos los beam candidates\n",
    "                topk_log_probs, topk_indices = torch.topk(log_probs, beam_width)\n",
    "\n",
    "                for k in range(beam_width):\n",
    "                    next_token = topk_indices[0][k].unsqueeze(0).unsqueeze(0)\n",
    "                    next_seq = torch.cat([seq, next_token], dim=1)\n",
    "                    next_score = score + topk_log_probs[0][k].item()\n",
    "                    new_beams.append((next_seq, hidden, next_score))\n",
    "\n",
    "            # Ordenamos y mantenemos los mejores beam_width candidatos\n",
    "            beams = sorted(new_beams, key=lambda x: x[2], reverse=True)[:beam_width]\n",
    "\n",
    "        # Retorna la mejor secuencia (la de mayor score)\n",
    "        best_seq = beams[0][0].squeeze().tolist()\n",
    "        return best_seq\n",
    "\n",
    "input_text = \"These mosquitoes are bugging me off\"\n",
    "tokens = [token2id.get(tok, token2id[\"<unk>\"]) for tok in input_text.split()]\n",
    "indices = [token2id.get(t, token2id[\"<unk>\"]) for t in tokens]\n",
    "src_tensor = torch.tensor(indices, dtype=torch.long)\n",
    "\n",
    "predicted_ids = beam_search(model, src_tensor, len(indices), token2id, beam_width=10)\n",
    "predicted_tokens = [id2token[i] for i in predicted_ids if i not in [token2id[\"<sos>\"], token2id[\"<eos>\"], token2id[\"<pad>\"]]]\n",
    "\n",
    "print(\"Respuesta generada:\", \" \".join(predicted_tokens))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLO_Old",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
